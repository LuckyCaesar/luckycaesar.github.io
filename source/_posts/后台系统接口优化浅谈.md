---
title: 后台系统接口优化浅谈
tags: [后台接口, 性能优化]
index_img: /img/dcf37cc6ff-manager.jpg
date: 2023-04-01 00:00:00
---



## 开头闲言

通常我们在谈到接口性能优化的时候，更多地是针对2C的、拥有大量用户的业务接口。这些接口的持续优化必不可少，因为用户流量就意味着收入，用户体验的优先级自然是非常高的。然而针对后台运营系统的接口，通常都比较“包容”，可能大部分系统能做到所谓的[2-5-10原则](https://blog.51cto.com/zdytesting/1734583)中的2秒级（甚至部分场景是5秒、10秒级）的响应即可。一是因为查询的数据量较大，二是后台运营场景下，并不是特别需要那么快速的响应，且运营人员的关注重点主要是在数据的完整性、准确性上。

当然，这并不意味着这些接口就可以“摆烂”。尤其是随着业务的扩张，运营效率的提升势在必行，而后端接口的优化首当其冲。在绝大部分业务场景下，查询无疑是最最最频繁的，后台系统当然也不例外。而且还多了一种形式 - 导出，只在返回结果上有差别。然后就是另外一种场景，导入。优化的重点也主要集中在这三种接口上面：*查询、导出、导入*。

本文仅做一些思路总结，具体细节不过多探究。



## 数据库表

这里主要是针对关系型数据库，最具代表也最常用的就是MySQL和Oracle了。

### 表设计

表结构设计是基础，这里简单整理下一些要点。更深入的设计规范和约束以及原理，推荐去阅读相关的书籍，譬如《高性能Mysql》。或者也可以参考一下类似阿里的《Java开发手册》总结的一些经验。

- 命名：精准，简要，规范。像Oracle推荐就是全部大写命名。
- 类型：选择合适的字段类型。
  - 变长数据`varchar`/`varchar2`
  - 定长数据`char`
  - 金额数字`decimal`/`number`
  - 状态/类别/年龄`tinyint`/`smallint`/`int`
  - ID类型`bigint`/`int`/`number`
  - 时间类型`date`/`datetime`/`timestamp`
  - 只有在特殊的情况下才允许使用`text`/`blob`等类型存储超长数据，且最好独立出一张表，主键关联
  - 编码类型，像MySQL现在一般都使用`utf8mb4`的编码，预防特殊字符
- 长度：为字段指定合适的长度，节省表及索引存储空间，更能提升检索速度。
  - 变长字符串，根据具体字段含义指定长度，也要记得预留空间。如姓名`varchar(20)`
  - 定长类型，如身份证号`char(18)`。*但是一般较少使用，固定长度可能为后续的扩展带来额外的改动成本*，比如要兼容存储企业的社会信用代码
  - 整型，如状态`tinyint(2)`，ID类`bigint(20)`或者`int(11)`
  - 金额，明确小数位精度和整数位长度，如`number(12,2)`或`decimal(12,2)`，10位整数，2位小数

- 冗余：如果是页面经常需要查询/导出的表，应该允许一定的字段冗余，方便展示，也避免了多表join或者再在程序中去调用RPC接口填充。
- 非空：必填字段标识为`NOT NULL`。既能在数据库层面做一个兜底的校验，也能保证字段的索引效率。

### 索引

选择合适的、常用的查询字段创建索引。单列索引、唯一索引、复合索引等等。关于MySQL和Oracle的索引创建及原理分析，有很多文章：

- [MySQL索引原理及慢查询优化](https://tech.meituan.com/2014/06/30/mysql-index.html)
- [轻松掌握Oracle索引](https://bbs.huaweicloud.com/blogs/114861)
- [关于Oracle索引建立的几个注意要点](https://bbs.huaweicloud.com/blogs/377021)

学会查看执行计划，关注索引类型、扫描行数，判断索引失效原因（类型隐式转换，file sort，左模糊/全模糊等等）。允许的情况下像MySQL也提供了`force index`手动强制指定索引，当然要慎重使用。

### 联表

**禁止出现过多的表join**！参考阿里《Java开发手册》：

> 【强制】超过三个表禁止 join。需要 join 的字段，数据类型保持绝对一致；多表关联查询时，保证被关联的字段需要有索引。
>
>   说明：即使双表 join 也要注意表索引、SQL 性能。

以前接触过这样的系统，一个查询有多达8张表的join。仅是取申请人/创建人/更新人/审批人等的全名/部门数据就出现了n次join，即使它们之间的join条件是有索引的USER_ID字段。分页后单页居然超过4s的响应。后续通过冗余常用的查询和展示字段为json格式，再使用[MySQL虚拟列](https://dev.mysql.com/doc/refman/8.0/en/create-table-generated-columns.html)来映射这些字段优化为2个表的join，大大的提升了查询效率，接口响应在400ms以内（非like查询）。

当然这只能说是一种奇技淫巧（这里还分享一个MySQL的奇技淫巧：[STRAIGHT_JOIN](https://cloud.tencent.com/developer/article/1193344)），最好还是在表设计阶段就能做好冗余。而且像上面的场景，其实这些员工的数据也应该作为快照留档，而不应该实时的取最新的数据，可能会造成误判，比如人员调岗。

另外，多表join，当表数据分布情况发生变化时，可能会让MySQL优化器对驱动表的选择发生变化。所以可能出现项目运行一段时间后SQL变慢，还得通过执行计划来判断如何调整join。

但是，如果确实需要较多表的连接怎么办呢？那跳出SQL层面，在代码里面把复杂的查询拆分成多个简单查询可能是比较好的选择。单个simple查询的效率还是很高的。



## 代码实现

代码实现层面的优化和数据库是相辅相成的。甚至可以说应用代码的设计还要显得更为重要一些。因为现如今流行的数据库，只要按照它们的要求去设计和构建表和索引，问题一般不会太大，大部分场景下交给自带的优化器足够了。

### 分页

页面查询的分页基本已经成了一种铁律，自不必多说。而针对导出也可以分页查询，分段写单个Sheet或者多个Sheet，像[EasyExcel](https://easyexcel.opensource.alibaba.com/docs/current/quickstart/write)就可以支持。当然也需要注意普通查询下的深度分页问题。

- [聊聊如何解决MySQL深分页问题](https://juejin.cn/post/7012016858379321358)
- [记录一次Oracle数据库千万级数据表的分页性能优化](https://www.cnblogs.com/happyflyingpig/p/15959609.html)
- [MyBatis 如何实现流式查询](https://segmentfault.com/a/1190000022478915)
- [大数据量查询：流式查询与游标查询](https://blog.csdn.net/m0_62375467/article/details/129714527)

### 循环与映射

查询时尽量直接使用SQL返回需要的字段，中间可能最多只是做一些DTO → VO的转换。

如果确实需要查询后循环处理一些逻辑或者补充一些字段信息（譬如微服务拆分后，需要通过RPC取一些基础信息），那尽量把循环中的I/O操作提到循环外，改为批量查询后再在内存中映射匹配。同样也适用于导入时的循环校验。

### 并行

一般是在导入/导出时使用。面对大量数据的导入/导出，可能还需要在循环中做一些校验/信息填充，即使是分页或者循环外批量查询映射后，也有可能还是达不到一个理想的响应速度，这时候就该并行处理登场了。

- 并行流/线程池：最标准的就是使用这两种方式。*但是并行流的使用要注意，其底层默认提供的线程池的并行度是跟CPU核心数挂钩的*。尤其是目前盛行微服务的容器化部署，可能单个pod的资源只有1个核心甚至少于1个核心，那“并行”其实就还是一个串行：

  ```java
  // ForkJoinPool#makeCommonPool() 并行度兜底设置
  if (parallelism < 0 && // default 1 less than #cores
      (parallelism = Runtime.getRuntime().availableProcessors() - 1) <= 0)// availableProcessors - JVM可用的处理器数量
      parallelism = 1;
  ```

  而且这个默认的池是整个应用程序通用的，所以如果代码中大量的使用并行流且不手动调整并行度（通过系统变量`java.util.concurrent.ForkJoinPool.common.parallelism`来调整，不推荐）的话，并不能提升处理效率。所以请在条件允许的情况下使用并行流，推荐还是自定义线程池。

  - [什么时候使用并行流 ](https://luckycaesar.github.io/article/%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E5%B9%B6%E8%A1%8C%E6%B5%81/)

  - [When to Use a Parallel Stream in Java](https://www.baeldung.com/java-when-to-use-parallel-stream)

- 协程/虚拟线程：这个在JDK 19中已经发布了[预览版本](https://openjdk.org/jeps/425)（随着JDK 21的发布，已经是[正式版](https://openjdk.org/jeps/444)了，实在是太快了orz）。国内像腾讯开源的[TencentKona](https://github.com/Tencent/TencentKona-8/wiki/KonaFiber%E7%94%A8%E6%88%B7%E6%96%87%E6%A1%A3-292)，移植了协程的特性，可以作为尝鲜和参考。在腾讯集团内部已经有核心业务迁移使用了。

  我尝试了一下，使用协程池可以将并行度提高至线程池的几十上百倍，基本上普通场景下的导入都可以做到*整个文件的处理时间 ≈ 单笔数据的处理时间*。当然作为池，在后台系统的使用场景中没必要设置如此之高的常驻核心线程数，仅作为测试。贴一下demo代码：

  ```java
  @Bean("fiberDemoExecutor")
  public Executor fiberDemoExecutor(FiberProperties fiberProperties) {
      ThreadPoolTaskExecutor poolExecutor = new ThreadPoolTaskExecutor();
      // 这里设置的coreSize=2000
      poolExecutor.setCorePoolSize(fiberProperties.getCoreSize());
      poolExecutor.setMaxPoolSize(fiberProperties.getMaxSize());
      poolExecutor.setKeepAliveSeconds(fiberProperties.getKeepAliveSeconds());
      poolExecutor.setQueueCapacity(fiberProperties.getQueueSize());
      poolExecutor.setThreadFactory(newThreadFactory(fiberProperties.getEnabled()));
      poolExecutor.setTaskDecorator((r) -> r);
      poolExecutor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy() {
          @Override
          public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
              String poolName = this.getClass().getSimpleName();
              log.warn(poolName + " is full, caller run");
              super.rejectedExecution(r, e);
          }
      });
      poolExecutor.initialize();
      return poolExecutor;
  }
  
  private static ThreadFactory newThreadFactory(boolean enabled) {
      if (enabled) {
          // 创建虚拟线程
          return Thread.ofVirtual()
              .name("fiber-demo-", 0)
              .uncaughtExceptionHandler((t, e) ->
                  log.error("thread [{}] got an unexpected exception.", t.getName(), e))
              .factory();
      }
      // 创建线程
      return Thread.ofPlatform()
          .name("fiber-demo-", 0)
          .factory();
  }
  
  @Component
  class ParallelDemo implements ApplicationListener<ApplicationStartedEvent> {
  
      @Resource
      private ThreadPoolTaskExecutor fiberDemoExecutor;
      
      @Override
      public void onApplicationEvent(ApplicationStartedEvent event) {
          // 协程模型
          CountDownLatch countDownLatch = new CountDownLatch(2000);
          StopWatch stopWatch = new StopWatch();
          stopWatch.start();
          IntStream.range(0, 2000).forEach(value -> fiberDemoExecutor.execute(() -> {
              try {
                  // 模拟业务逻辑执行时长
                  TimeUnit.MILLISECONDS.sleep(200);
              } catch (InterruptedException ignore) {
              }
              countDownLatch.countDown();
          }));
          try {
              countDownLatch.await();
          } catch (InterruptedException ignore) {
          }
          stopWatch.stop();
          // timespan-virtual-thread: 229ms
          System.out.println("timespan-virtual-thread: " + stopWatch.getTotalTimeMillis() + "ms");
  
          // 线程模型，并行流默认分配，i7-10700 8核16线程
          StopWatch stopWatch1 = new StopWatch();
          stopWatch1.start();
          IntStream.range(0, 2000).parallel().forEach(value -> {
              try {
                  // 模拟业务逻辑执行时长
                  TimeUnit.MILLISECONDS.sleep(200);
              } catch (InterruptedException ignore) {
              }
          });
          stopWatch1.stop();
          // timespan-thread: 31712ms
          System.out.println("timespan-thread: " + stopWatch1.getTotalTimeMillis());
      }
  }
  ```



## 方案设计

跳出具体实现，从更高一层的方案设计上的改进也是很有必要的。

### 数据库选型

针对不同的业务场景选择不同的数据库，譬如[什么场景应该用 MongoDB](https://developer.aliyun.com/article/64352)。海量日志数据的存储，可以选用ElasticSearch、Solr等。譬如用ES作埋点用户行为日志数据的存储，再在后台做分析统计。

### 数据库集群

像MySQL原生支持丰富的集群模式，如[Replication](https://dev.mysql.com/doc/refman/8.0/en/replication.html)、[Group Replication](https://dev.mysql.com/doc/refman/8.0/en/group-replication.html)、[InnoDB Cluster](https://dev.mysql.com/doc/refman/8.0/en/mysql-innodb-cluster-introduction.html)，以此为基础做读写分离设计。但是，[设计数据库集群读写分离并非易事](https://xie.infoq.cn/article/b26c3fcd77aba3f242ffcfeb4)。

### 分库分表

阿里《Java开发手册》：

> 【推荐】单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。 
>
> 说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。

当然，在业务数据膨胀的情况下，根据业务类型/渠道/来源/时间/取模等等规则进行分表/分区是也是很有必要的。

说到分表，可能大部分人都是想到一些中间件（[Apache ShardingSphere](https://shardingsphere.apache.org/index_zh.html)）。但其实也不一定非要引入第三方组件，比如自定义规则，页面固定分表条件，手动拼接表后缀来处理分表也未尝不可，好处是不会有较高的学习成本和过多的依赖，缺点当然是SQL不够“优雅”，写起来比较麻烦。且随着数据持续性膨胀，也无法满足更多的分表要求。譬如先按业务渠道横向拆分表，再对日志表或者超大业务表按时间/ID取模等等纵向拆分。

所以要不要分表，采用何种方式分表，就视具体业务而定了。

### Lucene

这里单独拎出来，是因为曾经利用Lucene实现过后台单据的综合搜索，不得不感叹倒排索引的设计之巧妙。而且ElasticSearch的底层核心就是它。在需要时，也可以尝试用它去做搜索优化。

### 定时任务

无需实时导出的业务，可以使用任务定时生成文件，提供下载。导入，提交任务，异步处理完成后通知。

而针对任务本身，可以引入类似Spring Batch的批处理框架来提升处理效率。或者针对集群化部署的大规模业务，引入分布式任务调度中间件如[XXL-JOB](https://www.xuxueli.com/xxl-job/)、[SchedulerX](https://www.aliyun.com/aliware/schedulerx)。再或者更高级的任务调度设计方案，[支付宝定时任务怎么做？三层分发任务处理框架介绍](https://mp.weixin.qq.com/s/6zY3ZtilM1jA5gMPMDRQyA)。

### 消息队列

同样的，有条件的情况下（可能有些后台系统并不会一开始就去依赖消息队列），也可以通过MQ来实现一些异步的处理，当然要注意消息丢失、重试、事务消息等等。

### 缓存

一般后台系统其实很少说大量使用缓存，利用缓存提升效率的场景一般出现在对外的接口或者热点数据里面。毕竟数据一致性的维护还是比较麻烦的，会增加额外的开发运维成本。当然有需求的情况下也可以做缓存。

- MyBatis/JPA：框架自带特性，多级缓存。但是一定要注意合理且正确的使用，否则出现数据不一致会很头疼。
- 本地/Redis缓存：本地缓存使用简单但是能力有限，Redis使用复杂且增加了依赖，但是功能强大适合分布式系统。需要手动控制数据一致性，根据业务类型，选择定时任务同步、监听事件实时更新、全量或增量更新、固定时间失效后重做缓存等等。



## 结尾碎语

以上，个人经验之谈，像个大杂烩，也没有什么“新”技术。但是，也想借此分享一个Github大佬的经典案例：[Partitioning GitHub’s relational databases to handle scale](https://github.blog/2021-09-27-partitioning-githubs-relational-databases-scale/)。其中提到的数字是亮点：

> In 2019, mysql1 answered 950,000 queries/s on average, 900,000 queries/s on replicas, and 50,000 queries/s on the primary.

Github截至2019年仍然使用的是MySQL“朴素的”一主多从集群模式，却能够支撑如此之大的访问量，不得不说在技术深度这一块儿确实是炉火纯青。也正如他总结里所说的：

> We often choose to leverage “boring” technology that has been proven to work at our scale, as reliability remains the primary concern. 

不盲目的追求“新”技术，使用久经考验的、所谓“无聊”的技术来构建高效稳定可靠的产品和服务，或许才是普通开发者们应该多多关注的。
